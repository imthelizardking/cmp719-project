{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyODzaI09TE4xvs86TgIhJCZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imthelizardking/cmp719-project/blob/main/cmp719_project_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main text"
      ],
      "metadata": {
        "id": "-ceqk4KZuraO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount gdrive for saving weights etc."
      ],
      "metadata": {
        "id": "q1NDzwFXuszW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!cd '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "9-vEFh6prUQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install torchvision package"
      ],
      "metadata": {
        "id": "Qc40ven2uvHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jiu1bGOdONc6",
        "outputId": "697fd03e-4413-46cd-cf96-ff73df47d5fd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required packages"
      ],
      "metadata": {
        "id": "6hRERpdouwyw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ua7XRff-OG-R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "#from torchvision.models import resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet-56 Model:"
      ],
      "metadata": {
        "id": "fp0wY1YCs9IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet-56 model\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet56(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNet56, self).__init__()\n",
        "        self.in_planes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(16, 9, stride=1)\n",
        "        self.layer2 = self._make_layer(32, 9, stride=2)\n",
        "        self.layer3 = self._make_layer(64, 9, stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * BasicBlock.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = nn.ReLU()(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = nn.AdaptiveAvgPool2d(1)(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "vQoHFy4iPJIn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set configuration for training ResNet-56 w/ cifar-100:"
      ],
      "metadata": {
        "id": "A3a-YsRwu0_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Define transforms for data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the ResNet-56 model\n",
        "model = ResNet56(num_classes=100).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg55HD5COLmp",
        "outputId": "f4cb0438-088c-4985-ecc4-58595109e363"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train ResNet-56 w/ cifar-100"
      ],
      "metadata": {
        "id": "0ScoZdfZu4F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(100):  # Number of epochs\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 99:  # Print every 100 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy on test set after epoch %d: %.2f %%' % (epoch + 1, accuracy))\n",
        "\n",
        "print('Training finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIMt9YZWqFX7",
        "outputId": "05dd5cc1-c055-4b34-a7b2-d6267a95c081"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 4.595\n",
            "[1,   200] loss: 4.507\n",
            "[1,   300] loss: 4.381\n",
            "Accuracy on test set after epoch 1: 2.88 %\n",
            "[2,   100] loss: 4.258\n",
            "[2,   200] loss: 4.244\n",
            "[2,   300] loss: 4.202\n",
            "Accuracy on test set after epoch 2: 4.18 %\n",
            "[3,   100] loss: 4.154\n",
            "[3,   200] loss: 4.135\n",
            "[3,   300] loss: 4.112\n",
            "Accuracy on test set after epoch 3: 4.10 %\n",
            "[4,   100] loss: 4.071\n",
            "[4,   200] loss: 4.043\n",
            "[4,   300] loss: 4.035\n",
            "Accuracy on test set after epoch 4: 5.83 %\n",
            "[5,   100] loss: 4.006\n",
            "[5,   200] loss: 3.993\n",
            "[5,   300] loss: 3.965\n",
            "Accuracy on test set after epoch 5: 8.21 %\n",
            "[6,   100] loss: 3.950\n",
            "[6,   200] loss: 3.995\n",
            "[6,   300] loss: 4.013\n",
            "Accuracy on test set after epoch 6: 7.75 %\n",
            "[7,   100] loss: 3.888\n",
            "[7,   200] loss: 3.880\n",
            "[7,   300] loss: 3.919\n",
            "Accuracy on test set after epoch 7: 9.69 %\n",
            "[8,   100] loss: 3.834\n",
            "[8,   200] loss: 3.853\n",
            "[8,   300] loss: 3.808\n",
            "Accuracy on test set after epoch 8: 10.87 %\n",
            "[9,   100] loss: 3.769\n",
            "[9,   200] loss: 3.754\n",
            "[9,   300] loss: 3.738\n",
            "Accuracy on test set after epoch 9: 10.69 %\n",
            "[10,   100] loss: 3.715\n",
            "[10,   200] loss: 3.710\n",
            "[10,   300] loss: 3.664\n",
            "Accuracy on test set after epoch 10: 13.16 %\n",
            "[11,   100] loss: 3.644\n",
            "[11,   200] loss: 3.627\n",
            "[11,   300] loss: 3.605\n",
            "Accuracy on test set after epoch 11: 14.02 %\n",
            "[12,   100] loss: 3.566\n",
            "[12,   200] loss: 3.563\n",
            "[12,   300] loss: 3.549\n",
            "Accuracy on test set after epoch 12: 15.53 %\n",
            "[13,   100] loss: 3.537\n",
            "[13,   200] loss: 3.522\n",
            "[13,   300] loss: 3.506\n",
            "Accuracy on test set after epoch 13: 16.21 %\n",
            "[14,   100] loss: 3.452\n",
            "[14,   200] loss: 3.451\n",
            "[14,   300] loss: 3.462\n",
            "Accuracy on test set after epoch 14: 18.34 %\n",
            "[15,   100] loss: 3.405\n",
            "[15,   200] loss: 3.403\n",
            "[15,   300] loss: 3.389\n",
            "Accuracy on test set after epoch 15: 18.47 %\n",
            "[16,   100] loss: 3.365\n",
            "[16,   200] loss: 3.367\n",
            "[16,   300] loss: 3.336\n",
            "Accuracy on test set after epoch 16: 18.54 %\n",
            "[17,   100] loss: 3.286\n",
            "[17,   200] loss: 3.295\n",
            "[17,   300] loss: 3.304\n",
            "Accuracy on test set after epoch 17: 19.78 %\n",
            "[18,   100] loss: 3.252\n",
            "[18,   200] loss: 3.269\n",
            "[18,   300] loss: 3.236\n",
            "Accuracy on test set after epoch 18: 21.46 %\n",
            "[19,   100] loss: 3.202\n",
            "[19,   200] loss: 3.203\n",
            "[19,   300] loss: 3.184\n",
            "Accuracy on test set after epoch 19: 21.95 %\n",
            "[20,   100] loss: 3.167\n",
            "[20,   200] loss: 3.139\n",
            "[20,   300] loss: 3.156\n",
            "Accuracy on test set after epoch 20: 22.75 %\n",
            "[21,   100] loss: 3.108\n",
            "[21,   200] loss: 3.117\n",
            "[21,   300] loss: 3.070\n",
            "Accuracy on test set after epoch 21: 23.94 %\n",
            "[22,   100] loss: 3.066\n",
            "[22,   200] loss: 3.071\n",
            "[22,   300] loss: 3.054\n",
            "Accuracy on test set after epoch 22: 23.93 %\n",
            "[23,   100] loss: 3.038\n",
            "[23,   200] loss: 3.025\n",
            "[23,   300] loss: 3.038\n",
            "Accuracy on test set after epoch 23: 23.78 %\n",
            "[24,   100] loss: 2.986\n",
            "[24,   200] loss: 2.998\n",
            "[24,   300] loss: 2.964\n",
            "Accuracy on test set after epoch 24: 23.26 %\n",
            "[25,   100] loss: 2.932\n",
            "[25,   200] loss: 2.929\n",
            "[25,   300] loss: 2.942\n",
            "Accuracy on test set after epoch 25: 27.00 %\n",
            "[26,   100] loss: 2.910\n",
            "[26,   200] loss: 2.919\n",
            "[26,   300] loss: 2.915\n",
            "Accuracy on test set after epoch 26: 27.43 %\n",
            "[27,   100] loss: 2.872\n",
            "[27,   200] loss: 2.857\n",
            "[27,   300] loss: 2.884\n",
            "Accuracy on test set after epoch 27: 26.90 %\n",
            "[28,   100] loss: 2.833\n",
            "[28,   200] loss: 2.864\n",
            "[28,   300] loss: 2.828\n",
            "Accuracy on test set after epoch 28: 26.76 %\n",
            "[29,   100] loss: 2.806\n",
            "[29,   200] loss: 2.832\n",
            "[29,   300] loss: 2.823\n",
            "Accuracy on test set after epoch 29: 29.42 %\n",
            "[30,   100] loss: 2.793\n",
            "[30,   200] loss: 2.790\n",
            "[30,   300] loss: 2.798\n",
            "Accuracy on test set after epoch 30: 29.44 %\n",
            "[31,   100] loss: 2.752\n",
            "[31,   200] loss: 2.760\n",
            "[31,   300] loss: 2.761\n",
            "Accuracy on test set after epoch 31: 30.07 %\n",
            "[32,   100] loss: 2.729\n",
            "[32,   200] loss: 2.735\n",
            "[32,   300] loss: 2.743\n",
            "Accuracy on test set after epoch 32: 29.24 %\n",
            "[33,   100] loss: 2.702\n",
            "[33,   200] loss: 2.718\n",
            "[33,   300] loss: 2.718\n",
            "Accuracy on test set after epoch 33: 29.65 %\n",
            "[34,   100] loss: 2.669\n",
            "[34,   200] loss: 2.678\n",
            "[34,   300] loss: 2.681\n",
            "Accuracy on test set after epoch 34: 30.70 %\n",
            "[35,   100] loss: 2.638\n",
            "[35,   200] loss: 2.654\n",
            "[35,   300] loss: 2.678\n",
            "Accuracy on test set after epoch 35: 32.42 %\n",
            "[36,   100] loss: 2.643\n",
            "[36,   200] loss: 2.633\n",
            "[36,   300] loss: 2.634\n",
            "Accuracy on test set after epoch 36: 30.56 %\n",
            "[37,   100] loss: 2.640\n",
            "[37,   200] loss: 2.620\n",
            "[37,   300] loss: 2.603\n",
            "Accuracy on test set after epoch 37: 31.63 %\n",
            "[38,   100] loss: 2.563\n",
            "[38,   200] loss: 2.608\n",
            "[38,   300] loss: 2.593\n",
            "Accuracy on test set after epoch 38: 30.76 %\n",
            "[39,   100] loss: 2.558\n",
            "[39,   200] loss: 2.588\n",
            "[39,   300] loss: 2.582\n",
            "Accuracy on test set after epoch 39: 30.47 %\n",
            "[40,   100] loss: 2.531\n",
            "[40,   200] loss: 2.561\n",
            "[40,   300] loss: 2.572\n",
            "Accuracy on test set after epoch 40: 31.58 %\n",
            "[41,   100] loss: 2.520\n",
            "[41,   200] loss: 2.548\n",
            "[41,   300] loss: 2.518\n",
            "Accuracy on test set after epoch 41: 32.65 %\n",
            "[42,   100] loss: 2.512\n",
            "[42,   200] loss: 2.504\n",
            "[42,   300] loss: 2.523\n",
            "Accuracy on test set after epoch 42: 33.30 %\n",
            "[43,   100] loss: 2.484\n",
            "[43,   200] loss: 2.474\n",
            "[43,   300] loss: 2.510\n",
            "Accuracy on test set after epoch 43: 33.11 %\n",
            "[44,   100] loss: 2.470\n",
            "[44,   200] loss: 2.469\n",
            "[44,   300] loss: 2.495\n",
            "Accuracy on test set after epoch 44: 34.77 %\n",
            "[45,   100] loss: 2.457\n",
            "[45,   200] loss: 2.461\n",
            "[45,   300] loss: 2.446\n",
            "Accuracy on test set after epoch 45: 34.21 %\n",
            "[46,   100] loss: 2.423\n",
            "[46,   200] loss: 2.443\n",
            "[46,   300] loss: 2.459\n",
            "Accuracy on test set after epoch 46: 34.62 %\n",
            "[47,   100] loss: 2.423\n",
            "[47,   200] loss: 2.420\n",
            "[47,   300] loss: 2.441\n",
            "Accuracy on test set after epoch 47: 34.80 %\n",
            "[48,   100] loss: 2.415\n",
            "[48,   200] loss: 2.434\n",
            "[48,   300] loss: 2.417\n",
            "Accuracy on test set after epoch 48: 35.56 %\n",
            "[49,   100] loss: 2.391\n",
            "[49,   200] loss: 2.381\n",
            "[49,   300] loss: 2.431\n",
            "Accuracy on test set after epoch 49: 35.01 %\n",
            "[50,   100] loss: 2.372\n",
            "[50,   200] loss: 2.386\n",
            "[50,   300] loss: 2.392\n",
            "Accuracy on test set after epoch 50: 35.18 %\n",
            "[51,   100] loss: 2.356\n",
            "[51,   200] loss: 2.346\n",
            "[51,   300] loss: 2.398\n",
            "Accuracy on test set after epoch 51: 35.75 %\n",
            "[52,   100] loss: 2.330\n",
            "[52,   200] loss: 2.356\n",
            "[52,   300] loss: 2.386\n",
            "Accuracy on test set after epoch 52: 36.84 %\n",
            "[53,   100] loss: 2.338\n",
            "[53,   200] loss: 2.335\n",
            "[53,   300] loss: 2.362\n",
            "Accuracy on test set after epoch 53: 35.17 %\n",
            "[54,   100] loss: 2.328\n",
            "[54,   200] loss: 2.312\n",
            "[54,   300] loss: 2.368\n",
            "Accuracy on test set after epoch 54: 36.06 %\n",
            "[55,   100] loss: 2.294\n",
            "[55,   200] loss: 2.325\n",
            "[55,   300] loss: 2.324\n",
            "Accuracy on test set after epoch 55: 36.47 %\n",
            "[56,   100] loss: 2.291\n",
            "[56,   200] loss: 2.325\n",
            "[56,   300] loss: 2.297\n",
            "Accuracy on test set after epoch 56: 35.24 %\n",
            "[57,   100] loss: 2.297\n",
            "[57,   200] loss: 2.307\n",
            "[57,   300] loss: 2.281\n",
            "Accuracy on test set after epoch 57: 37.90 %\n",
            "[58,   100] loss: 2.281\n",
            "[58,   200] loss: 2.266\n",
            "[58,   300] loss: 2.325\n",
            "Accuracy on test set after epoch 58: 38.08 %\n",
            "[59,   100] loss: 2.270\n",
            "[59,   200] loss: 2.271\n",
            "[59,   300] loss: 2.266\n",
            "Accuracy on test set after epoch 59: 36.09 %\n",
            "[60,   100] loss: 2.254\n",
            "[60,   200] loss: 2.255\n",
            "[60,   300] loss: 2.263\n",
            "Accuracy on test set after epoch 60: 37.31 %\n",
            "[61,   100] loss: 2.231\n",
            "[61,   200] loss: 2.251\n",
            "[61,   300] loss: 2.256\n",
            "Accuracy on test set after epoch 61: 38.54 %\n",
            "[62,   100] loss: 2.218\n",
            "[62,   200] loss: 2.253\n",
            "[62,   300] loss: 2.230\n",
            "Accuracy on test set after epoch 62: 38.89 %\n",
            "[63,   100] loss: 2.222\n",
            "[63,   200] loss: 2.220\n",
            "[63,   300] loss: 2.251\n",
            "Accuracy on test set after epoch 63: 39.02 %\n",
            "[64,   100] loss: 2.177\n",
            "[64,   200] loss: 2.192\n",
            "[64,   300] loss: 2.245\n",
            "Accuracy on test set after epoch 64: 37.86 %\n",
            "[65,   100] loss: 2.189\n",
            "[65,   200] loss: 2.223\n",
            "[65,   300] loss: 2.228\n",
            "Accuracy on test set after epoch 65: 38.22 %\n",
            "[66,   100] loss: 2.166\n",
            "[66,   200] loss: 2.181\n",
            "[66,   300] loss: 2.197\n",
            "Accuracy on test set after epoch 66: 37.71 %\n",
            "[67,   100] loss: 2.190\n",
            "[67,   200] loss: 2.173\n",
            "[67,   300] loss: 2.187\n",
            "Accuracy on test set after epoch 67: 38.05 %\n",
            "[68,   100] loss: 2.171\n",
            "[68,   200] loss: 2.201\n",
            "[68,   300] loss: 2.196\n",
            "Accuracy on test set after epoch 68: 39.25 %\n",
            "[69,   100] loss: 2.156\n",
            "[69,   200] loss: 2.195\n",
            "[69,   300] loss: 2.197\n",
            "Accuracy on test set after epoch 69: 38.49 %\n",
            "[70,   100] loss: 2.139\n",
            "[70,   200] loss: 2.158\n",
            "[70,   300] loss: 2.170\n",
            "Accuracy on test set after epoch 70: 35.33 %\n",
            "[71,   100] loss: 2.122\n",
            "[71,   200] loss: 2.143\n",
            "[71,   300] loss: 2.198\n",
            "Accuracy on test set after epoch 71: 39.66 %\n",
            "[72,   100] loss: 2.154\n",
            "[72,   200] loss: 2.141\n",
            "[72,   300] loss: 2.161\n",
            "Accuracy on test set after epoch 72: 40.27 %\n",
            "[73,   100] loss: 2.129\n",
            "[73,   200] loss: 2.133\n",
            "[73,   300] loss: 2.149\n",
            "Accuracy on test set after epoch 73: 36.12 %\n",
            "[74,   100] loss: 2.096\n",
            "[74,   200] loss: 2.144\n",
            "[74,   300] loss: 2.142\n",
            "Accuracy on test set after epoch 74: 40.18 %\n",
            "[75,   100] loss: 2.114\n",
            "[75,   200] loss: 2.121\n",
            "[75,   300] loss: 2.108\n",
            "Accuracy on test set after epoch 75: 39.51 %\n",
            "[76,   100] loss: 2.076\n",
            "[76,   200] loss: 2.129\n",
            "[76,   300] loss: 2.139\n",
            "Accuracy on test set after epoch 76: 40.09 %\n",
            "[77,   100] loss: 2.084\n",
            "[77,   200] loss: 2.102\n",
            "[77,   300] loss: 2.109\n",
            "Accuracy on test set after epoch 77: 40.34 %\n",
            "[78,   100] loss: 2.068\n",
            "[78,   200] loss: 2.114\n",
            "[78,   300] loss: 2.115\n",
            "Accuracy on test set after epoch 78: 39.96 %\n",
            "[79,   100] loss: 2.091\n",
            "[79,   200] loss: 2.104\n",
            "[79,   300] loss: 2.091\n",
            "Accuracy on test set after epoch 79: 39.63 %\n",
            "[80,   100] loss: 2.071\n",
            "[80,   200] loss: 2.074\n",
            "[80,   300] loss: 2.103\n",
            "Accuracy on test set after epoch 80: 39.83 %\n",
            "[81,   100] loss: 2.058\n",
            "[81,   200] loss: 2.102\n",
            "[81,   300] loss: 2.077\n",
            "Accuracy on test set after epoch 81: 38.40 %\n",
            "[82,   100] loss: 2.045\n",
            "[82,   200] loss: 2.059\n",
            "[82,   300] loss: 2.114\n",
            "Accuracy on test set after epoch 82: 40.31 %\n",
            "[83,   100] loss: 2.049\n",
            "[83,   200] loss: 2.027\n",
            "[83,   300] loss: 2.086\n",
            "Accuracy on test set after epoch 83: 40.73 %\n",
            "[84,   100] loss: 2.033\n",
            "[84,   200] loss: 2.050\n",
            "[84,   300] loss: 2.086\n",
            "Accuracy on test set after epoch 84: 40.78 %\n",
            "[85,   100] loss: 2.053\n",
            "[85,   200] loss: 2.054\n",
            "[85,   300] loss: 2.050\n",
            "Accuracy on test set after epoch 85: 38.71 %\n",
            "[86,   100] loss: 2.063\n",
            "[86,   200] loss: 2.023\n",
            "[86,   300] loss: 2.044\n",
            "Accuracy on test set after epoch 86: 40.87 %\n",
            "[87,   100] loss: 2.030\n",
            "[87,   200] loss: 2.033\n",
            "[87,   300] loss: 2.048\n",
            "Accuracy on test set after epoch 87: 41.46 %\n",
            "[88,   100] loss: 2.033\n",
            "[88,   200] loss: 2.030\n",
            "[88,   300] loss: 2.037\n",
            "Accuracy on test set after epoch 88: 39.15 %\n",
            "[89,   100] loss: 2.029\n",
            "[89,   200] loss: 2.024\n",
            "[89,   300] loss: 2.019\n",
            "Accuracy on test set after epoch 89: 40.91 %\n",
            "[90,   100] loss: 2.010\n",
            "[90,   200] loss: 2.010\n",
            "[90,   300] loss: 2.039\n",
            "Accuracy on test set after epoch 90: 41.00 %\n",
            "[91,   100] loss: 2.001\n",
            "[91,   200] loss: 2.015\n",
            "[91,   300] loss: 2.023\n",
            "Accuracy on test set after epoch 91: 42.06 %\n",
            "[92,   100] loss: 2.000\n",
            "[92,   200] loss: 1.969\n",
            "[92,   300] loss: 2.012\n",
            "Accuracy on test set after epoch 92: 40.32 %\n",
            "[93,   100] loss: 1.958\n",
            "[93,   200] loss: 2.022\n",
            "[93,   300] loss: 2.009\n",
            "Accuracy on test set after epoch 93: 42.11 %\n",
            "[94,   100] loss: 1.965\n",
            "[94,   200] loss: 2.003\n",
            "[94,   300] loss: 2.005\n",
            "Accuracy on test set after epoch 94: 41.76 %\n",
            "[95,   100] loss: 1.965\n",
            "[95,   200] loss: 1.974\n",
            "[95,   300] loss: 1.996\n",
            "Accuracy on test set after epoch 95: 41.75 %\n",
            "[96,   100] loss: 1.980\n",
            "[96,   200] loss: 1.986\n",
            "[96,   300] loss: 1.992\n",
            "Accuracy on test set after epoch 96: 40.67 %\n",
            "[97,   100] loss: 1.946\n",
            "[97,   200] loss: 1.981\n",
            "[97,   300] loss: 2.002\n",
            "Accuracy on test set after epoch 97: 40.78 %\n",
            "[98,   100] loss: 1.964\n",
            "[98,   200] loss: 1.956\n",
            "[98,   300] loss: 1.953\n",
            "Accuracy on test set after epoch 98: 41.89 %\n",
            "[99,   100] loss: 1.964\n",
            "[99,   200] loss: 1.958\n",
            "[99,   300] loss: 1.966\n",
            "Accuracy on test set after epoch 99: 42.58 %\n",
            "[100,   100] loss: 1.958\n",
            "[100,   200] loss: 1.963\n",
            "[100,   300] loss: 1.927\n",
            "Accuracy on test set after epoch 100: 41.61 %\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save trained ResNet-56 weights:"
      ],
      "metadata": {
        "id": "vClLBAJtuUmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/719_project/trained_weights/resnet_model_weights.pth')"
      ],
      "metadata": {
        "id": "-gahXtc9dc0l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Top-1 accuracy for trained ResNet-56 model and cifar-100 dataset (in paper, 70.43%):"
      ],
      "metadata": {
        "id": "fjgi4ZDmuXFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # for making sure there is no training, just inference\n",
        "    model.eval()  # model to eval. mode\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "top1_accuracy = 100 * correct / total\n",
        "print('Top-1 Accuracy: {:.2f}%'.format(top1_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xra3b6yxsrkU",
        "outputId": "f1f8a1f4-ee56-4462-8f09-b89406757ee6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 Accuracy: 41.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vision Transformer w/ Feature Guidance:**"
      ],
      "metadata": {
        "id": "x_f-1YhVwFmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vision Transformer w/ feature guidance:"
      ],
      "metadata": {
        "id": "Lyc2MRLQwzO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Vision Transformer model\n",
        "class VisionTransformer_fg(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim):\n",
        "        super(VisionTransformer_fg, self).__init__()\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = 3 * patch_size ** 2  # Assuming RGB images\n",
        "\n",
        "        self.patch_embedding = nn.Sequential(\n",
        "            nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
        "            nn.Flatten(start_dim=2)\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(dim, heads, dim_feedforward=mlp_dim),\n",
        "            num_layers=depth\n",
        "        )\n",
        "        self.classifier = nn.Linear(dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=0)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YX26rgWHwHo6"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set training configuration for Vision Transformer w/ feature guidance"
      ],
      "metadata": {
        "id": "QecnTTJPwges"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up hyperparameters and data loaders\n",
        "torch.cuda.empty_cache()\n",
        "image_size = 32\n",
        "patch_size = 4\n",
        "num_classes = 100\n",
        "dim = 64\n",
        "depth = 10\n",
        "heads = 8\n",
        "mlp_dim = 512\n",
        "batch_size = 128\n",
        "learning_rate = 2e-3\n",
        "epochs = 50\n",
        "BETA = 2.5 # scaler for feature guidance loss\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Create an instance of the model\n",
        "model_ViT = VisionTransformer_fg(image_size, patch_size, num_classes, dim, depth, heads, mlp_dim)\n",
        "model_ViT.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_ViT.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "# Create data loaders (replace with your own datasets)\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qPmWYBzwl6x",
        "outputId": "45063a9a-be86-46d4-d045-5f74e7523344"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If pre-trained weights will be used, run following code snippet:"
      ],
      "metadata": {
        "id": "f3mUQRs2y0V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ViT.load_state_dict(torch.load('/content/drive/MyDrive/719_project/trained_weights/ViT_model_weights.pth'))"
      ],
      "metadata": {
        "id": "HfN4ByVJy4d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vision Transformer Trainer:"
      ],
      "metadata": {
        "id": "q5tBSOANwJum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "model.eval() # no training for cnn, just eval.\n",
        "model_ViT.train()\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # zero grads\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model_ViT(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    avg_train_loss = train_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_train_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o86la3xZ-SZS",
        "outputId": "338d2309-cb3b-4e82-b56d-68067ed47285"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Loss: 4.3355\n",
            "Epoch 2/50 - Loss: 4.1358\n",
            "Epoch 3/50 - Loss: 4.0879\n",
            "Epoch 4/50 - Loss: 4.0400\n",
            "Epoch 5/50 - Loss: 4.0203\n",
            "Epoch 6/50 - Loss: 4.0016\n",
            "Epoch 7/50 - Loss: 3.9860\n",
            "Epoch 8/50 - Loss: 3.9627\n",
            "Epoch 9/50 - Loss: 3.9445\n",
            "Epoch 10/50 - Loss: 3.9293\n",
            "Epoch 11/50 - Loss: 3.9234\n",
            "Epoch 12/50 - Loss: 3.9071\n",
            "Epoch 13/50 - Loss: 3.8969\n",
            "Epoch 14/50 - Loss: 3.8862\n",
            "Epoch 15/50 - Loss: 3.8693\n",
            "Epoch 16/50 - Loss: 3.8637\n",
            "Epoch 17/50 - Loss: 3.8477\n",
            "Epoch 18/50 - Loss: 3.8432\n",
            "Epoch 19/50 - Loss: 3.8401\n",
            "Epoch 20/50 - Loss: 3.8300\n",
            "Epoch 21/50 - Loss: 3.8285\n",
            "Epoch 22/50 - Loss: 3.8180\n",
            "Epoch 23/50 - Loss: 3.8208\n",
            "Epoch 24/50 - Loss: 3.8183\n",
            "Epoch 25/50 - Loss: 3.8107\n",
            "Epoch 26/50 - Loss: 3.8141\n",
            "Epoch 27/50 - Loss: 3.8118\n",
            "Epoch 28/50 - Loss: 3.8036\n",
            "Epoch 29/50 - Loss: 3.8044\n",
            "Epoch 30/50 - Loss: 3.8022\n",
            "Epoch 31/50 - Loss: 3.8012\n",
            "Epoch 32/50 - Loss: 3.7956\n",
            "Epoch 33/50 - Loss: 3.7909\n",
            "Epoch 34/50 - Loss: 3.7810\n",
            "Epoch 35/50 - Loss: 3.7878\n",
            "Epoch 36/50 - Loss: 3.7763\n",
            "Epoch 37/50 - Loss: 3.7681\n",
            "Epoch 38/50 - Loss: 3.7632\n",
            "Epoch 39/50 - Loss: 3.7536\n",
            "Epoch 40/50 - Loss: 3.7497\n",
            "Epoch 41/50 - Loss: 3.7527\n",
            "Epoch 42/50 - Loss: 3.7452\n",
            "Epoch 43/50 - Loss: 3.7430\n",
            "Epoch 44/50 - Loss: 3.7459\n",
            "Epoch 45/50 - Loss: 3.7488\n",
            "Epoch 46/50 - Loss: 3.7421\n",
            "Epoch 47/50 - Loss: 3.7397\n",
            "Epoch 48/50 - Loss: 3.7357\n",
            "Epoch 49/50 - Loss: 3.7331\n",
            "Epoch 50/50 - Loss: 3.7285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Top-1 Accuracy for Vision Transformer w/ feature guidance:"
      ],
      "metadata": {
        "id": "Vs5z4OQCKIU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ViT.state_dict(), '/content/drive/MyDrive/719_project/trained_weights/ViT_model_weights.pth')"
      ],
      "metadata": {
        "id": "At_C5tkjrna9"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # for making sure there is no training, just inference\n",
        "    correct, total = 0, 0\n",
        "    model_ViT.eval()  # model to eval. mode\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model_ViT(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "top1_accuracy = 100 * correct / total\n",
        "print('Top-1 Accuracy: {:.2f}%'.format(top1_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K79DxOQaKChG",
        "outputId": "b050e391-e167-4500-f4f9-d613feb42c7e"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 Accuracy: 11.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEMP:"
      ],
      "metadata": {
        "id": "f00AkMq0_mNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training loop\n",
        "def train_ViT_with_fg(model_ViT, model_cnn, dataloader, criterion, optimizer, device, BETA):\n",
        "\n",
        "    ###def get_features_hook(module, input, output):\n",
        "      #### Store the intermediate features in a global variable\n",
        "      ###global student_features\n",
        "      ###student_features = output\n",
        "    ###def get_teacher_features_hook(module, input, output):\n",
        "        #### Store the intermediate features in a global variable\n",
        "        ###global teacher_features\n",
        "        ###teacher_features = output\n",
        "\n",
        "    model_cnn.eval() # no training for cnn, just eval.\n",
        "    model_ViT.train()\n",
        "    total_loss = 0.0\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        #images, labels = images.cuda(), labels.cuda() # add this line\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_ViT(images)\n",
        "\n",
        "        #### hook cnn and ViT for intermediate feature extraction #\n",
        "        ###criterion_fg = nn.MSELoss()\n",
        "        ###model_ViT.register_forward_hook(get_features_hook)\n",
        "        #### Register a forward hook to extract features from the teacher model\n",
        "        ###model_cnn.register_forward_hook(get_teacher_features_hook)\n",
        "        ####loss_fg = criterion_fg(student_features, teacher_features.detach())  # detach the teacher features to prevent backpropagation through the teacher\n",
        "        ###loss_fg = 0\n",
        "        # hook cnn and ViT for intermediate feature extraction #\n",
        "        loss_cls = criterion(outputs, labels) # cross-entropy loss\n",
        "        loss = loss_cls + BETA * 0 # loss_fg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "    return total_loss / len(dataloader.dataset)"
      ],
      "metadata": {
        "id": "OYTQvwCu_puJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}